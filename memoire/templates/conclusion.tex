\begin{kwote}
``Les outils façonnent la pensée. Ce que nous pouvons penser et ce que nous pouvons dire résulte d’une dynamique dans laquelle les outils et les techniques jouent un rôle fondamental.''\footcite[p.31]{epron_ledition_2018}
\end{kwote}

\citeauthor{epron_ledition_2018} avancent l'idée selon laquelle les outils ne sont pas de simples instruments passifs, mais des acteur dans la construction de la pensée. Ils ne se limitent pas à faciliter des tâches, mais façonnent une conceptualisation du monde et des idées. Les outils de la recherche, qu'ils soient numériques ou analogiques, structurent des gestes intellectuels. Les outils numériques ne sont pas de simples remédiations des outils traditionnels. Ils offrent de nouvelles possibilités, de nouvelles façons d'interagir avec l'information et de la manipuler. Ils peuvent catalyser les dynamiques collaboratives autour de ces nouvelles méthodes et ces nouvelles perceptives. Un cadre technique contient un cadre conceptuel, et il y a donc un enjeu à forger des outils de traitement de la donnée qui vont dans le sens du partage des pratiques.

Ce travail s'est attaché à exposer l'importance et les moyens de partager le développement et l'utilisation des outils numériques de la recherche, en prenant pour exemple l'application du \dl à la sémantification et l'enrichissement des sources en histoire de l'astronomie. Les questionnements, impliquant la modélisation, l'accès à la donnée, et l'élaboration des modèles de \cv, s'orientent vers la conception d'un \si dédié à des documents numérisés variés et hétérogènes, et au traitement de leurs éléments visuels. Les outils de \dl sont mis à disposition via une plateforme web modulaire et réemployable dans différents contextes (\aikon).

La première partie de ce mémoire, qui portait sur le contexte disciplinaire des projets \eida/\vhs, a mis en évidence la complexité des données traitées, ainsi que la diversité des besoins des chercheur.ses. En conséquence, une modélisation de données flexible et interopérable, ne renonçant pas aux exigences de description des sources, a constitué un axe de réflexion. Par ailleurs, la variété des modes d'accès aux données est une piste d'analyse importante. Les données visuelles et les besoins spécifiques des historien.nes, notamment l'accès à leurs propres images stockées localement, nécessitent des solutions techniques adaptées. Bien que \iiif offre un cadre prometteur pour l'échange de données volumineuses, il ne constitue pas une solution universelle.

Dans un second temps, nous avons présenté sur les enjeux et défis liés à l'utilisation du \dl et de la \cv dans le traitement des données historiques, notamment les moyens de gérer la faible disponibilité de corpus annotés. Nous nous sommes ensuite penché sur une application des traitements d'\ia, en dressant les exigences fonctionnelles d'un outil d'édition des \svgs (sorties de l'algorithme de vectorisation) intégré à la plateforme. Cet outil a vocation à fédérer les pratiques des chercheur.ses pour l'édition des diagrammes astronomiques. 

La troisième partie est consacrée aux spécificités techniques de la conception d'une plateforme modulaire destinée à héberger les outils de gestion de données et les instruments de \cv. Cette plateforme présente une architecture modulaire, reposant sur une séparation claire des fonctionnalités dans des modules et des composants applicatifs distincts. L'inférence des modèles, qui exige une puissance de calcul importante, est optimisée par l'utilisation d'un \gpu sur lequel tourne une \api prévue à cet effet. Par ailleurs, le choix d'une bibliothèque \textit{front-end} permet de créer des interfaces utilisateur.rice performantes, facilitant ainsi l'interaction des chercheur.ses avec un processus de travail itératif, alternant phases de traitement par les modèles de vision et corrections afin de garantir la qualité des résultats. Ces derniers constituent des corpus annotés qualitatifs qui pourront être réutilisés dans le cadre de l'entraînement des modèles. 

\textit{La modularité des outils~: pourquoi~?} 

Cette étude de cas a montré l'importance de l'accessibilité et du partage au sein de la communauté de la recherche, non seulement des données, mais aussi des outils qui vont permettre de les traiter. Cette démarche favorise à la fois l'évolutivité et la pérennité des outils numériques, permet d'établir des pratiques communes au sein de la communauté scientifique et, enfin, démocratise l'accès à des outils innovants qui ouvrent de nouvelles perspectives d'analyse des sources.

Les outils taillés trop spécifiquement sur un projet ou sur une question de recherche sont fragiles. Leur cycle de vie est intimement lié aux financements, ce qui les expose à l'obsolescence dès lors que les ressources s'épuisent. De tels développements, souvent coûteux en temps et en moyens (financiers comme humains), ne garantissent pas la pérennité des outils. Pour assurer leur survie et favoriser leur évolution, il est alors intéressant de s'inscrire dans des projets collaboratifs, et en conséquence, d'adopter une approche modulaire. En fédérant les efforts et en mutualisant les ressources, il est possible non seulement de stimuler l'innovation mais aussi de garantir la maintenance à long terme de ces outils, les rendant ainsi plus robustes et pérennes.

L'ouverture des outils et l'extensivité des chaînes de traitement des données a aussi des implications scientifiques d'importance. Ces aspects inscrivent une démarche scientifique dans l'optique de la collaboration et du partage des pratiques, favorisant leur reproductibilité, et renforçant la transparence des méthodes. On l'aura évoqué dans le \hyperlink{chapitre-6-vers-edition}{chapitre 6}, la diversité des pratiques d'édition scientifique des diagrammes présents dans les traités d'histoire des sciences témoigne de la richesse des points de vue sur les sources, mais peut aussi constituer un obstacle à la coopération au sein du champ de recherche. La multiplication des outils, des méthodologies et des normes entraîne une fragmentation des pratiques et remet en question l'utilité scientifique des contenus produits. Chaque chercheur.se ou chaque équipe développe ses propres outils, avec ses propres formats, et ses normes adaptées à leur angle d'approche épistémologique et heuristique. Devant ce constat, l'élaboration d'un outil d'édition numérique peut alors porter un cadre de travail partageable. 

S'adapter à l'hétérogénéité des données et des contextes matériels ne favorise pas seulement la collaboration et la cohérence des pratiques au sein d'un champ de recherche, mais facilite également l'accès aux outils d'\ia pour l'analyse à grande échelle des corpus, ouvrant ainsi de nouvelles perspectives sur les sources.

La plateforme \aikon et son interface charpentent alors un véritable environnent de recherche numérique, dédié à l'analyse des sources, orienté vers l'interprétation par les chercheur.ses. En centralisant les ressources et en offrant des fonctionnalités d'annotation et de visualisation, cet outil fait office de nouveau laboratoire, et change la manière dont les chercheur.ses interagissent avec les données historiques, permettant au domaine des études visuelles d'exploiter le paradigme du \textit{big data}. Elle est conçue pour s'adapter au traitement de documents numérisés divers, pour exploiter les éléments graphiques qu'ils contiennent.

\textit{Un outil généraliste et adaptable à plusieurs projets de recherche~: comment~?}

Le cas \aikon a en outre permis d'identifier les principaux enjeux liés à la mise en œuvre de la modularité. Nous nous sommes interrogés sur les fondements d'un outil suffisamment polyvalent et offrant une base solide pour permettre sa spécialisation.

Premièrement, la modélisation de la donnée est un aspect à considérer. Se référer à des modèles conceptuels standards est alors essentiel pour disposer de concepts larges et adaptables aux données du patrimoine. Si le modèle de données adopté n'est pas taillé spécifiquement pour décrire les source de \eida, il est néanmoins suffisamment précis pour répondre aux besoins actuels des chercheur.ses, et bénéficie de sa généralité pour s'adapter aux sources de \vhs et à une grande diversité de types de documents, permettant l'étude des éléments graphiques qu'ils contiennent. 

Le domaine de recherche de la \cv, dans son essence même, illustre en outre les dynamiques collaboratives dans la construction des instruments de traitement de la donnée. En partant de modèles génériques pré-entraînés, il est possible de construire des architectures complexes spécialisées sur des tâches et des données particulières. Pour assurer la cohérence et la réutilisabilité des données, il est important d'encourager l'utilisation de vocabulaires contrôlés et de normes pour l'annotation des données.

Une attention particulière a été portée aux interfaces de la plateforme \aikon, pour faciliter le travail des chercheur.ses et la diffusion de données. Un outil doté d'une interface graphique accueille un vaste éventail d'utilisateur.rice et anticipe en outre la médiation des résultats des recherches vers un public plus large. 

D'autre part, le recours à des protocoles standards et interopérables, tels que le \iiif, assure la compatibilité des systèmes. Les formats de sortie des traitements sont aussi des formats libres et manipulables~: \textsc{txt}, Numpy ou \svg. 

La personnalisation s'exprime par ailleurs dans le fait qu'\aikon peut être déployée dans différents environnements matériels, la possibilité d'installation en locale démontrant sa légèreté et sa portabilité. Mais les problématiques liées à l'ouverture et la modularité du code concernent aussi la conception d'une architecture qui puisse s'adapter à une augmentation du volume de données et du nombre d'utilisateur.rices. Ainsi les besoins côté ingénierie vont parfois rentrer en conflit avec cette volonté de légèreté si importante pour inclure un maximum de contextes de recherche et d'utilisateur.rices différents. La gestion de volumes de données croissants ou des outils d'\ia plus lourds requiert du matériel et des architectures applicatives plus robustes que celles développées avec les moyens des laboratoire de recherche en \shs. Pour l'instant, \aikon est taillé pour -- et utilisé sur -- des corpus qui, bien que larges, restent limités comparés aux collections des bibliothèques par exemple. Un passage à l'échelle reposerait sur l'implication de consortiums ou d'institutions, qui disposent des technologies et des infrastructures capables de gérer de grandes quantités de données de manière efficace. Nous conclurons et ouvrirons sur cette idée~: la recherche constitue le terreau de l'innovation~; néanmoins, son passage à l'échelle institutionnelle exige des compétences en ingénierie qui transcendent ceux des projets de recherche, même collaboratifs.